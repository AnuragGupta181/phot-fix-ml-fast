# ğŸ“¸ FotoFix ML Server

A productionâ€‘ready **FastAPIâ€‘based ML server** that combines:

* ğŸ” **YOLO object detection**
* ğŸ§  **OCR text extraction (Tesseract)**
* âœ‚ï¸ **Background removal (rembg)**

Built for imageâ€‘centric workflows such as document processing, photo cleanup, and smart image analysis.

---

## ğŸš€ Features

* YOLOv8 object detection (CPUâ€‘optimized)
* OCR using Tesseract (pytesseract)
* Highâ€‘quality background removal
* Base64 encoded image responses
* Robust error handling & validation
* CORS enabled for frontend usage

---

## ğŸ› ï¸ Tech Stack

* **FastAPI**
* **Ultralytics YOLO**
* **Tesseract OCR**
* **pytesseract**
* **rembg**
* **Pillow (PIL)**
* **Uvicorn**

---

## ğŸ“ Project Structure

```
phot-fix-ml-fast/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ uploads/
â”‚   â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ best11.pt
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## âš™ï¸ Local Setup (Ubuntu)

### 1ï¸âƒ£ System Dependencies

Install **Tesseract OCR**:

```bash
sudo apt-get update
sudo apt-get install -y tesseract-ocr
```

ğŸ“ Default binary path:

```
/usr/bin/tesseract
```

This is already configured in the code:

```python
pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"
```

---

### 2ï¸âƒ£ Python Environment

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Run the Server

```bash
uvicorn src.server:app --reload
```

Server will start at:

```
http://127.0.0.1:8000
```

Interactive docs:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ“¡ API Endpoints

### ğŸ”¹ GET /

Service info and available routes.

**Response**

```json
{
  "message": "YOLO + OCR + Background API",
  "routes": {
    "POST /detect": "YOLO object detection",
    "POST /remove-bg": "Remove image background",
    "POST /extract-text": "OCR text extraction"
  }
}
```

---

### ğŸ”¹ GET /health

Health check endpoint.

**Response**

```json
{
  "status": "success",
  "message": "Server healthy",
  "code": 200
}
```

---

### ğŸ”¹ POST /detect

Run YOLO object detection on an image.

**Request**

* `file` (multipart/formâ€‘data)

**Response**

```json
{
  "boxes": [...],
  "classes": [...],
  "confidences": [...],
  "encoded_image": "<base64>"
}
```

---

### ğŸ”¹ POST /remove-bg

Remove background from an image.

**Request**

* `file` (multipart/formâ€‘data)

**Response**

```json
{
  "encoded_image": "<base64>"
}
```

---

### ğŸ”¹ POST /extract-text

Extract text using OCR.

**Request**

* `file` (multipart/formâ€‘data)

**Response**

```json
{
  "extracted_text": "Detected text from image"
}
```

---

## ğŸ§ª Notes

* All inference runs on **CPU** by default
* Temporary files are autoâ€‘cleaned after processing
* Base64 responses are frontendâ€‘friendly

---

## ğŸ“¦ Deployment

* Works on **AWS EC2 / VPS / Docker**
* No GPU required
* Expose using:

```bash
uvicorn src.server:app --host 0.0.0.0 --port 8500
```

---

## ğŸ§  Use Cases

* Document OCR pipelines
* ID / card scanning
* Photo background removal
* Object detection microservices

---

## ğŸ‘¨â€ğŸ’» Author

Built by **Anurag Gupta** ğŸš€

If you want a **Dockerâ€‘only README**, **Swagger examples**, or **frontend integration guide**, just say the word.
